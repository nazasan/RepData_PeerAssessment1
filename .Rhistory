install.packages("KernSmooth")
library()
library(KernSmooth)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of lenght 1 indicating
## the location of the CSV files.
## 'pollutant' is a character vector of lenght 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used.
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values).
## Obtain the data
##setwd(directory)
filenames <- list.files(directory, pattern = "*.*", full.names = TRUE)
for (i in id) {
if (!exists("data")){
data <- read.csv(filenames[i])
cname <- names(data)       # get column names when reading in header
}
else if (exists("data")){
temp_data <- read.csv(filenames[i])
names(temp_data) <- cname          # assign column names so you can bind
data <-rbind(data, temp_data)
rm(temp_data)
}
## Ignoring missing values (NA)
if (pollutant == "sulfate") {
good <- complete.cases(data[,2])
m <- mean(data[good,2])
}
else if (pollutant == "nitrate") {
good <- complete.cases(data[,3])
m <- mean(data[good,3])
}
else {
return ("Error")
}
## Calculate mean
m
}
pollutantmean()
## These functions cache the inverse of a matrix
## This function creates a special "matrix" object that can cache its inverse
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
## superoperator caches in the global enviroment
set <- function(y) {
x <<- y
inv <<- NULL
}
## gets the value
get <- function() x
## set to a local variable the parameter
setInverse <- function(inverse) inv <<- inverse
getInverse <- function() inv
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
## This function computes the inverse of the special "matrix" returned by
## makeCacheMatrix
cacheSolve <- function(x) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
## Return a matrix that is the inverse of 'x'
inv
}
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
amatrix
amatrix$get()
cacheSolve(amatrix)
amatrix$getinverse()
amatrix$getInverse()
cacheSolve(amatrix)
amatrix$set(matrix(c(0,5,99,66), nrow=2, ncol=2))
cacheSolve(amatrix)
amatrix$get()
amatrix$getInverse()
amatrix$get()
p <- makeCacheMatrix(c(1,2,1,3),nrow=2,ncol=2)
p <- makeCacheMatrix(matrix(c(1,2,1,3),nrow=2,ncol=2))
p
p$get()
x
p$x
inv
p$set(matrix(c(1,1,1,1)))
p$get()
p$setInverse()
p$setInverse(matrix(c(2,2,2,2)))
p$getInverse()
inv
cacheSolve(p)
p$set(matrix(c(1,1,1,1)))
p$getInverse()
cacheSolve(p)
p$set(matrix(c(1,1,1,1),nrow=2,ncol=2))
p$getInverse()
p$get()
cacheSolve(p)
p$getInverse()
p$set(matrix(c(1,1,1,1),nrow=2,ncol=2))
cacheSolve(p)
p$set(matrix(c(1,2,1,3),nrow=2,ncol=2))
cacheSolve(p)
p$getInverse()
library(datasets)
data(iris)
?iris
iris
iris$Species=="virginica"
iris[1,Species="virginica"]
subset(iris,Species=="virginica")
subset(iris[1,],Species=="virginica")
subset(iris[Sepal.Lenght],Species=="virginica")
subset(iris$Sepal.Lenght,Species=="virginica")
s<-subset(iris,Species=="virginica")
s
mean(s[,1])
apply(iris[, 1:4], 2, mean)
apply(iris, 1, mean)
rowMeans(iris[, 1:4])
apply(iris[, 1:4], 1, mean)
data(mtcats)
data(mtcars)
?mtcars
sapply(split(mtcars$mpg, mtcars$cyl), mean)
mtcars[,2]
sapply(split(mtcars$hp, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)[1]
sapply(split(mtcars$hp, mtcars$cyl), mean)[3]
sapply(split(mtcars$hp, mtcars$cyl), mean)[1]-sapply(split(mtcars$hp, mtcars$cyl), mean)[3]
debug(ls)
ls
ls
sapply(split(mtcars$hp, mtcars$cyl), mean)[1]-sapply(split(mtcars$hp, mtcars$cyl), mean)[3]
sapply(split(mtcars$hp, mtcars$cyl), mean)[3]-sapply(split(mtcars$hp, mtcars$cyl), mean)[1]
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
dpois?
?dpois
?dpois
?qpois
setwd("~/Desktop/Coursera/RepData_PeerAssessment1")
data <- read.csv(activity.csv)
data <- read.csv("activity.csv")
data <- read.csv("activity.csv")
data <- read.csv("activity.csv")
data
View(data)
steps_per_day <- ddply(data, .(date), summarize, steps = sum(steps))
library(plyr)
steps_per_day <- ddply(data, .(date), summarize, steps = sum(steps))
steps_per_day
plot(steps_per_day$date, steps_per_day$steps, type = "h", col = "red", xlab = "Date",
ylab = "Steps per day")
hist(steps_per_day$steps,
col = "red", xlab = "Global Active Power (kilowatts)",main="")
plot(steps_per_day$date, steps_per_day$steps, type = "h", col = "red", xlab = "Date",
ylab = "Steps per day")
?plot
barplot(steps_per_day$steps, names.arg=steps_per_day$date, xlab="Date", ylab="Steps")
mean(steps_per_day$steps)
?mean
mean(steps_per_day$steps, na.rm = TRUE)
median(steps_per_day$steps, na.rm = TRUE)
steps_per_interval <- ddply(data, .(interval), summarize, steps = mean(steps))
steps_per_interval
steps_per_interval <- ddply(data, .(interval), summarize, steps = mean(steps, na.rm = TRUE))
steps_per_interval
plot(steps_per_interval, type="l")
´´´{r echo = TRUE}
library(plyr)
steps_per_interval <- ddply(data, .(interval), summarize, steps = mean(steps, na.rm = TRUE))plot(steps_per_interval, type="l")
´´´
steps_per_interval$interval[which.max(steps_per_interval$steps)]
data <- read.csv("activity.csv")
sum(is.na(data))
data_2 <- data[is.na(data)] <- 0
data_2
data2[is.na(data)] <- 0
data2 <- data.frame()
data2[is.na(data)] <- 0
data2[is.na(data$steps)] <- 0
data2
is.na(data¢steps)
is.na(data$steps)
data$steps
View(data)
steps_per_interval$interval[which.max(steps_per_interval$steps)]
data <- read.csv("activity.csv")
is.na(data$steps)
is.na(data$steps)
data2 <- data
data2[is.na(data2$steps)] <- 0
View(data2)
is.na(data2$steps) <- 0
View(data2)
data2[is.na(data2$steps)] <- 0
is.na(data2$steps) <- 0
View(data2)
is.na(data2$steps)
data2[is.na(data2$steps)] <- 0
View(data2)
data2[is.na(data$steps)] <- 0
data2 <- data
View(data)
View(data2)
data2[is.na(data2)] <- 0
View(data2)
